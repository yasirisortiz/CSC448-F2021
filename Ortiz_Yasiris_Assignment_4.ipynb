{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "id": "S8PKiVJaL_AW",
    "outputId": "23c2a4cd-0c53-4a1c-c454-7ed87e392a8c"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yasirisortiz/CSC448-F2021/blob/main/Ortiz_Yasiris_Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and pip installations\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A05Q5B0_NUX9"
   },
   "source": [
    "# Part 1: Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "id": "YZ4MUsbXNZ0P",
    "outputId": "77e7a628-792f-4d28-b7b1-e06f4db3efd3"
   },
   "outputs": [],
   "source": [
    "# Load the dataset (load remotely, not locally)\n",
    "iris_data = datasets.load_iris()\n",
    "\n",
    "\n",
    "# Covert sklearn dataset to a Pandas dataframe\n",
    "# The target is represented with the following: 0 for Setosa, 1 for Versicolor, and 2 for Virginica.\n",
    "df = pd.DataFrame(data= np.c_[iris_data['data'], iris_data['target']],\n",
    "                     columns= iris_data['feature_names'] + ['target'])\n",
    "\n",
    "# Output the first 15 rows of the data\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a summary of the table information (number of datapoints, etc.)\n",
    "# print(\"Table's Summary\")\n",
    "# print()\n",
    "\n",
    "# it displays basic info about the datatypes and the number of samples\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of the numerical data of the dataset \n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRMtsJKBaxWu"
   },
   "source": [
    "## About the dataset\n",
    "\n",
    "The Iris Dataset is a multi-class classification flower dataset that contains 150 records from three different types of species: Iris setosa, Iris versicolor and Iris virginica. This dataset is useful as a beginner dataset for machine learning purposes. \n",
    "\n",
    "The features of this dataset are:\n",
    "- sepal length(cm)\n",
    "- sepal width (cm)\n",
    "- petal length(cm)\n",
    "- petal length(cm)\n",
    "\n",
    "The label is:\n",
    "- Target (which refers to the species)\n",
    "\n",
    "The mapping:\n",
    "- Iris Setosa : 0\n",
    "- Iris Versicolor : 1\n",
    "- Iris Virginica : 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhKaIrZKNaHg"
   },
   "source": [
    "# Part 2: Split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OrgogB62NcOi",
    "outputId": "7bbfb1ea-88ed-4944-ab94-48696b9a71df"
   },
   "outputs": [],
   "source": [
    "# Take the dataset and split it into our features (X) and label (y)\n",
    "#X,y = df.iloc[:,:-1].values, df.iloc[:,-1].values\n",
    "\n",
    "# X, y = iris_data.data, iris_data.target\n",
    "\n",
    "features = df[[\"sepal length (cm)\", \"petal length (cm)\",\"sepal width (cm)\", \"petal width (cm)\"]] # X\n",
    "label = df[\"target\"] # y\n",
    "X, y = features, label \n",
    "\n",
    "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.10)\n",
    "x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hblF-ei9Ncia"
   },
   "source": [
    "# Part 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IhFhEN03Nf7o",
    "outputId": "15a94661-020b-4520-b5f3-c34fdfb042f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yasirisortiz/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# i. Use sklearn to train a LogisticRegression model on the training set\n",
    "log_reg_model  = LogisticRegression().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability for each possible class:  [[0.96127011 0.00697149 0.0317584 ]]\n"
     ]
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "log_model_prob = log_reg_model.predict_proba(np.array([[1,2,3,4]]))\n",
    "print(\"Probability for each possible class: \", log_model_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for the Logistic Regression Model:  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# iii. Report on the score for Logistic regression model, what does the score measure?\n",
    "log_model_score = log_reg_model.score(x_test, y_test)\n",
    "print(\"The score for the Logistic Regression Model: \", log_model_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does the score measure?\n",
    "It measures the performance or accuracy of the Logistic Regression model. The score 93% means that this is the chance of classifying correclty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients from the model are:  [[-0.39390109 -2.46030348  0.94584346 -1.05295622]\n",
      " [ 0.45355879 -0.16024439 -0.30773901 -0.9060864 ]\n",
      " [-0.05965769  2.62054787 -0.63810445  1.95904263]] \n",
      "\n",
      "Intercepts from the model are:  [  9.46015811   2.33620048 -11.79635858] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iv. Extract the coefficents and intercepts for the boundary line(s)\n",
    "\n",
    "# coefficients\n",
    "coefficients = log_reg_model.coef_\n",
    "print(\"Coefficients from the model are: \", coefficients , \"\\n\")\n",
    "\n",
    "# intercept \n",
    "intercept  = log_reg_model.intercept_\n",
    "print(\"Intercepts from the model are: \", intercept , \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDUpXQN4Nilk"
   },
   "source": [
    "# Part 4: Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVMs are a set of supervised learning methods used for classification, regression and outliers detection. \n",
    "Source from: https://scikit-learn.org/stable/modules/svm.html#svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U__zukpdNqiQ",
    "outputId": "5cd81a50-9137-4f36-842e-0687e9bc7c45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to train a Support Vector Classifier on the training set\n",
    "\n",
    "svm_model = SVC(probability=True)\n",
    "svm_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability for each possible class:  [2.]\n"
     ]
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "# 0: Setosa\n",
    "# 1: Versicolor\n",
    "# 2: Virginica\n",
    "\n",
    "# predict_proba will give the possibility of each class given the sample point\n",
    "# The model predicts that each of the probabilities belongs to each class [0,1,2]\n",
    "svm_pred = svm_model.predict(np.array([[1,2,3,4]]))\n",
    "print(\"Probability for each possible class: \", svm_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 means that the probability is for Virginica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the SVC Clasification is:  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# iii. Report on the score for the SVM, what does the score measure?\n",
    "# it measures that the classification is %93 correct\n",
    "svm_model_score = svm_model.score(x_test, y_test)\n",
    "print(\"Accuracy of the SVC Clasification is: \", svm_model_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULoL7mMBNrlS"
   },
   "source": [
    "# Part 5: Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CKKmODVrN9lQ",
    "outputId": "dced24f7-c6bd-45fb-c68f-87548e9228dc"
   },
   "outputs": [],
   "source": [
    "# i. Use sklearn to train a Neural Network (MLP Classifier) on the training set\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_model = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(15,),random_state=1).fit(features, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability for each possible class:  [[0.00000000e+00 2.30561959e-12 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "mlp_model_pred = mlp_model.predict_proba(np.array([[1,2,3,4]]))\n",
    "print(\"Probability for each possible class: \", mlp_model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Neural Network Clasification is:  1.0\n"
     ]
    }
   ],
   "source": [
    "# iii. Report on the score for the Neural Network, what does the score measure?\n",
    "mlp_model_score = mlp_model.score(x_test, y_test)\n",
    "print(\"Accuracy of the Neural Network Clasification is: \", mlp_model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yasirisortiz/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# iv: Experiment with different options for the neural network, report on your best configuration (the highest score I was able to achieve was 0.8666)\n",
    "mlp_model = MLPClassifier(solver='sgd', alpha=1e-5,hidden_layer_sizes=(15,),random_state=1).fit(features, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bi5tDwHmC28"
   },
   "source": [
    "# Part 6: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCFlfJy2mCg6",
    "outputId": "e71bf88c-6418-4b7f-e289-4acf743c16cc"
   },
   "outputs": [],
   "source": [
    "# i. Use sklearn to 'train' a k-Neighbors Classifier\n",
    "# Declare an of the KNN classifier class with the value with neighbors.\n",
    "knn_model = KNeighborsClassifier(n_neighbors=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=9)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: KNN is a nonparametric model and technically doesn't require training\n",
    "# fit will essentially load the data into the model see link below for more information\n",
    "# https://stats.stackexchange.com/questions/349842/why-do-we-need-to-fit-a-k-nearest-neighbors-classifier\n",
    "\n",
    "# Fit the model with training data and target values\n",
    "knn_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability for each possible class:  [[0.55555556 0.33333333 0.11111111]]\n"
     ]
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "knn_model_pred = knn_model.predict_proba([[1,2,3,4]])\n",
    "print(\"Probability for each possible class: \", knn_model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the K-Nearest Neighbors Clasification is:  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# iii. Report on the score for kNN, what does the score measure?\n",
    "knn_model_score = knn_model.score(x_test,y_test)\n",
    "print(\"Accuracy of the K-Nearest Neighbors Clasification is: \", knn_model_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "162Sw3LeoqE2"
   },
   "source": [
    "# Part 7: Conclusions and takeaways\n",
    "\n",
    "In your own words describe the results of the notebook. Which model(s) performed the best on the dataset? Why do you think that is? Did anything surprise you about the exercise?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somethig I notice from this notebook and using the Iris dataset with these four different classifications was that the performance score was very similar for all of them. And that there were more changes when working with the sample datapoint and predicting the values for each flower class. For me, two of the models with the best performance were Support Vector Machine and K-Nearest Neighbors Clasification. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
